{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8739,"status":"ok","timestamp":1634657264733,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"6YycCOPSjNJK","outputId":"a92b77a9-0888-407c-87e1-d770aad042e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 4.2 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 48.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 37.6 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 35.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting huggingface-hub>=0.0.17\n","  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"-gXTZxuQjLQw"},"source":["# GPT-2 for tweet generation"]},{"cell_type":"markdown","metadata":{},"source":["## Plain, without any finetuning\n","Just to see what will happen\n","Do not run the following cells if you want to finetune"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12310,"status":"ok","timestamp":1634569233605,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"E72pXjw4to_3","outputId":"0e11cd18-bd95-4ec8-a9e2-da346c7faa80"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n","Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.11.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n","Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.11.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n","Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.11.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n","loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n","loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n","Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.11.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n"]}],"source":["from transformers import pipeline, set_seed\n","generator = pipeline('text-generation', model='gpt2')\n","set_seed(42)"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2938,"status":"ok","timestamp":1634569236509,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"TiICdk2wt3bi","outputId":"46829ee0-5a68-4262-b912-ecd0c8221d94"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"data":{"text/plain":["[{'generated_text': \"The plandemic is for big pharma, not small farmers. For everyone who's sick and needs better health help, there's a huge problem\"},\n"," {'generated_text': \"The plandemic is for big pharma and in particular biotech. The American pharma has been working under President Obama's watch for the past six\"},\n"," {'generated_text': 'The plandemic is for big pharma,\" said Haidt. \"People are paying all the prices. But why should we pay for every'},\n"," {'generated_text': 'The plandemic is for big pharma lobbyists.\"\\n\\nThe industry\\'s top lobbyist, William B. McCaul Jr., who previously served as'},\n"," {'generated_text': 'The plandemic is for big pharma, not low-cost health care. It\\'s not a clean or healthy business model.\"\\n\\nHealth'}]"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["generator(\"The plandemic is for big pharma\", max_length=30, num_return_sequences=5)"]},{"cell_type":"markdown","metadata":{"id":"qsdTmBWVkFPi"},"source":["# Fine-tuning the model"]},{"cell_type":"markdown","metadata":{"id":"pzR67m0Umeq-"},"source":["## Load data"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28346,"status":"ok","timestamp":1634657293064,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"lKVfm8oR4rKf","outputId":"7308dc13-08c9-47da-bcc8-bb2ebb1fe639"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["#mount drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29595,"status":"ok","timestamp":1634657331464,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"FC7MTCEnuZmx","outputId":"6e5054f6-3072-4bd5-8bbc-67164801e836"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import pandas as pd\n","import nltk\n","nltk.download('punkt')\n","import numpy as np\n","import seaborn as sns\n","from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1634657331493,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"ya3zsH0r-3JK","outputId":"023b547b-2b00-4f94-e102-8f4070a9561c"},"outputs":[{"name":"stdout","output_type":"stream","text":["      id  tweetid                                               text\n","0      2        1  There's a trail that MSS is checking that allo...\n","1      3        1  Why didn’t any of the “spiritual mediums” pred...\n","2      4        1  sfw?  defend the coincidence of Corona, Wuhan ...\n","3      5        1  Why isn’t Fonda &amp;her narcissistic , selfis...\n","4      6        1  They've done this for decades but #coronavirus...\n","..   ...      ...                                                ...\n","494  496        1  Indians are realising the contributions of our...\n","495  497        2  Yesterday a client called into my work (you kn...\n","496  498        1  Let us Pray  Heavenly Father we pray unto you ...\n","497  499        1  I don't say Sanjay Gandhi was right, but he wa...\n","498  500        1  The conspiracy theory presented by this work o...\n","\n","[499 rows x 3 columns]\n"]}],"source":["# load into a data frame\n","df = pd.read_csv(\"dev-1-task-1.csv\") \n","df.columns = [\"id\", \"tweetid\", \"text\"]\n","print(df)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":372},"executionInfo":{"elapsed":688,"status":"ok","timestamp":1634657332140,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"cKsH2sU0OCQA","outputId":"30471c18-1cd2-46af-bb3b-1c7db527311c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:316: UserWarning: Dataset has 0 variance; skipping density estimate. Pass `warn_singular=False` to disable this warning.\n","  warnings.warn(msg, UserWarning)\n"]},{"data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f792a712ed0>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["doc_lengths = []\n","\n","for row in df:\n","\n","    # get rough token count distribution\n","    tokens = nltk.word_tokenize(row)\n","\n","    doc_lengths.append(len(tokens))\n","\n","doc_lengths = np.array(doc_lengths)\n","\n","sns.distplot(doc_lengths)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1634657333106,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"H0e2ZM51vHIU","outputId":"4ceba7c1-ee9f-47ed-fe7d-4a6a16cf8c03"},"outputs":[{"data":{"text/plain":["[\"There's a trail that MSS is checking that allowed the designer-bioweapon into China in the first place. In my opinion, CIA introduced SARS targeting China previously. Novel Coronavirus is round 2, another destabilizing mega-weapon in their godless inhuman arsenal! IMPO 🇨🇳🕵️\\u200d♀️\",\n"," 'Why didn’t any of the “spiritual mediums” predict the #2020 #CoronavirusOutbreak? Not even with “I feel the letters C and V, they will become important”? Well, because there r no valid “mediums”. But if you know somebody who did and is (valid medium) please reply here. 🔮 #Corona',\n"," 'sfw?\\xa0 defend the coincidence of Corona, Wuhan Lab, Gates Foundation, Pirbright Inst., and timing of many deep state implosions in recent weeks.\\xa0\\xa0 Dial a distraction in full flex.\\xa0 Transfer rate and death rate are not flu like.',\n"," 'Why isn’t Fonda &amp;her narcissistic , selfish , wealthy buddies in Wuhan China protesting against the communist Chinese gov bioweapons &amp;the egregious negligence of spreading a deadly virus throughout the world , “allegedly!” 😆',\n"," 'They\\'ve done this for decades but #coronavirus empowers them to grab more people and have a good \"cover\" for it. Status quo for the Sheeple.\\xa0\\xa0 And we have ignorant Bernie supporters who won\\'t study WORLD HISTORY &amp; learn from countries who have suffered under Socialism/Communism!',\n"," \"We do have Coronavirus in Vietnam but so far only 15 people got it, thanks to the Government's urgent action. It's not OK to discriminate foreigners while their countries are suffer both economically and spiritually because of an unknown Virus. That's just displaying evil.\",\n"," '\"Avoiding\" conflict with the US is a strategy for defeat. The only way to defeat the Western Banking Cartel is to take the fight to them otherwise they will wipe you out like with the Covid-19 bioweapon stealth attack.They will do ANYTHING to maintain their control over the world',\n"," \"I'd heard of the Wuhan bioweapons labs a few weeks ago, didn't see any reason to pursue further, seemed coincidental. But the PRC shutting down its economy, triggering longterm changes, that doesn't seem a plausible reaction to a new wet-market virus. With lack of transparency...\",\n"," \"I took a container of lysol wipes and looked at the back and it indeed does say helps with human coronavirus. How can it be a new disease when it's been on lysol containers for a long time? It isnt new,that's how. Someone is using it for biological warfare? Population control?\",\n"," 'The fact that it has so easily circumvented containment and spread around the world suggests to me that it isn’t a bioweapon. You don’t want a bioweapon that will gradually make its way back to you. But I still think accidental release from the Wuhan lab could be possible.']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["texts = df.text.tolist()\n","texts[0:10]"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":1120,"status":"ok","timestamp":1634660923660,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"GWHj6fG2YQjX"},"outputs":[],"source":["len_texts = [len(text) for text in texts]"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":406,"status":"ok","timestamp":1634660944261,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"B1iv26r1YjZa","outputId":"de0fbd57-b716-41f9-8556-3854e3d78fe0"},"outputs":[{"data":{"text/plain":["292"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["max(len_texts)"]},{"cell_type":"markdown","metadata":{"id":"FwcGlpbYmjz1"},"source":["## GPT2 tokenizer"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162,"referenced_widgets":["0081feb9317c4b02b0190693164a2290","cab85c09a1064fe0ba145a106ee451b2","37dee43e729c4a5ba323acfc7176ac3b","43be20e036df4e6980889fe9a7a5bc06","269f32d79447482dbb3e634657e77471","8c677bb84e694a2bb66686296891c426","fd40e57b47b140fda0113d9f68b23865","dc17d638155f496093df2d4e9ca684ed","cbf1a1f733bb49b6baafd1d7f495f567","8b361618b18546bd846abac804311604","0cf1935b34bc459c9eeb9832480ac9ad","0c7ccb171728459ab106e746afca2920","dea063e377404ccbaea5620061fb55b9","112e5a4104c44c7e8573da1a8010e33d","71350ebc54b0441c8b3cbc3e128f6842","7c164b2d6c4d4b77a895f1140b6f3101","9afa5041d5514f84b9ea72c4c9ad761e","2828ab7f7d0947ac9aa8f52e07f48ac9","2165e4f009c54c70bed544a77895891d","935dc7764eb54b29a36eeacb324aa716","bf66e7d854b249de9048f30f824e20ed","fac2a585434845e28640ef9c40adc0e8","b4166945930f4bbba4759109755e303a","9201fd5d910749d78d758152bfff8ee2","f9a5e7b3ac1348caa93e91a8b4608c42","b97d2bc4ba244f37b350c13dc3a7f09e","b9fa959f463f478ca96adb9d42d01e23","00d8354dd2884cd88d0017006d95d17d","a15460efe08a4f599476b61459344c0e","13b94ea2511d47bf98c4636c91823d75","858d0f9bd2744c9d8688f2bafc15f364","4d09c54bf56040fc8c406f4a0f4aa84e","970bffc8108f4c16ae623b96256c7395","664c819fac2b4d9bb52b16f9f975fe2e","90ce56d75dcc41d2becb09d265c679a1","6efe7e6806f245c5829a2adcd99d02a6","b245b692484541d98ebf661bab185528","c82d7b7d4fa7409d8c89997b035c63c6","47e153f3aab54aefa8943f5a4d16511b","569daf2a38d54cada721acce5ed8175a","d793ea9185614f5db7f22bc1bd019a06","5d4827f5b2634ae288e8b5056d089fec","2024d9557a914e7094875c82cd3009d8","5cb1e163142241308fc9edef779c6e4d"]},"executionInfo":{"elapsed":12579,"status":"ok","timestamp":1634657345681,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"Z474sSC6oe7A","outputId":"62ae44a8-7f94-42c3-a578-99611ec58053"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0081feb9317c4b02b0190693164a2290","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c7ccb171728459ab106e746afca2920","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4166945930f4bbba4759109755e303a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"664c819fac2b4d9bb52b16f9f975fe2e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# Load the GPT tokenizer.\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1634657345683,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"sh0XKuDvnryn","outputId":"34c09bad-121d-47bd-da70-4592efdea3f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n","The beginning of sequence token <|startoftext|> token has the id 50257\n","The end of sequence token <|endoftext|> has the id 50256\n","The padding token <|pad|> has the id 50258\n"]}],"source":["print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n","print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n","print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n","print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"]},{"cell_type":"markdown","metadata":{"id":"kg8wwIf7mvL-"},"source":["## Data Loaders"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1634657345685,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"ANPspf2aw8WS"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1634657345686,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"U_XJVIetKN-h"},"outputs":[],"source":["class GPT2Dataset(Dataset):\n","\n","  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n","\n","    self.tokenizer = tokenizer\n","    self.input_ids = []\n","    self.attn_masks = []\n","\n","    for txt in txt_list:\n","\n","      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n","\n","      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n","      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n","    \n","  def __len__(self):\n","    return len(self.input_ids)\n","\n","  def __getitem__(self, idx):\n","    #{\"input_ids\": [...], \"labels\": [...], \"attention_mask\": [..]}.\n","    return {\"input_ids\":self.input_ids[idx], \"labels\": self.input_ids[idx], \"attention_mask\": self.attn_masks[idx] }"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1002,"status":"ok","timestamp":1634657346677,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"Xza_O1_rD7yh"},"outputs":[],"source":["dataset = GPT2Dataset(texts, tokenizer, max_length=768)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1634657346679,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"em08LHwixXpx","outputId":"ef90f489-157a-4104-a7d2-2b2e73b81f7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["  449 training samples\n","   50 validation samples\n"]}],"source":["# Split into training and validation sets\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"]},{"cell_type":"markdown","metadata":{"id":"TWtQOgYr67To"},"source":["# Models"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1634657346680,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"PoSJd9eg7GCh"},"outputs":[],"source":["from transformers import AdamW, get_linear_schedule_with_warmup\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Tell pytorch to run this model on the GPU.\n","device = torch.device(\"cuda\")\n","#model.cuda()\n","\n","#Tell pytroch to run on cpu \n","#device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["c6f95fa6b505444eace63e80addd944a","9953b5fc35204b2c9e791443d0bcf126","49d2887879f8483ea46d9d1d3d299e0d","eaa55cdcd1404c73b167f0941a28a895","76b385985f83406bba82305726b5c090","7713a36eccb441ce8344563c1f4b372f","6eb2eab05dde42c3b7646426f318eef4","587d7dae793f4cfbb8f1ee44f5854b14","6b27f89826424784b3f9c2d64068a554","15bb09417d314b90aaf7b23a84712409","0611c6c06451410e85916077f63c0708"]},"executionInfo":{"elapsed":21033,"status":"ok","timestamp":1634657367703,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"QO6JtGrL69wZ","outputId":"545e7c7a-8443-4ba5-861c-7c9213b49262"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6f95fa6b505444eace63e80addd944a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# I'm not really doing anything with the config\n","configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n","\n","# instantiate the model\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n","\n","# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n","# otherwise the tokenizer and model tensors won't match up\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 17\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":19528,"status":"ok","timestamp":1634657387226,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"plauSzD_kHJy"},"outputs":[],"source":["from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=3,              # total number of training epochs\n","    per_device_train_batch_size=2,  # batch size per device during training\n","    per_device_eval_batch_size=2,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    #logging_dir='./logs',            # directory for storing logs\n","    logging_steps=10,\n",")\n","\n","trainer = Trainer(\n","    model=model,                         # the instantiated 🤗 Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=val_dataset             # evaluation dataset\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":687951,"status":"ok","timestamp":1634658075164,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"On1UnxtVkNSI","outputId":"c852c54a-cf59-48f2-c1dc-c311b29b519b"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 449\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 675\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [675/675 11:26, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>8.949700</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>8.427600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>7.961200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>7.360200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>6.298000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>5.251400</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>3.416900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.729900</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>1.055700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.703000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.560100</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.525100</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.467300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.508700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.459400</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.483000</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.428900</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.389400</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.489300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.440700</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.407100</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.390800</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.483200</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.382800</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.360000</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.376000</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.360100</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.395400</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.391600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.378600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.384800</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.359200</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.365200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.370200</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.373400</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.359600</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.345500</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.377600</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.339000</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.343200</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.415000</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.335700</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.359800</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.349000</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.351400</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.359900</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.313000</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.331700</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.343100</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.317500</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.362700</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.326900</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.293600</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.339500</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.319900</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.322200</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.325400</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.303100</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.300400</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.316900</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.338800</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.306300</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>0.330200</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>0.336500</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.333900</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>0.303000</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>0.332000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=675, training_loss=1.0749393812815349, metrics={'train_runtime': 687.4012, 'train_samples_per_second': 1.96, 'train_steps_per_second': 0.982, 'total_flos': 527940550656000.0, 'train_loss': 1.0749393812815349, 'epoch': 3.0})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2158,"status":"ok","timestamp":1634658077293,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"fuXDjXF54m25"},"outputs":[],"source":["#Save model\n","model_save_name = 'gpt2-finetune-twitter.pt'\n","path = F\"/content/gdrive/My Drive/{model_save_name}\" \n","torch.save(model.state_dict(), path)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18712,"status":"ok","timestamp":1634659072388,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"Z0nHplJtRUl5","outputId":"f74c265f-3163-450d-a15c-422c61cd74b2"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n","Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.11.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["#Reload model, can skip if doing all at once\n","\n","# I'm not really doing anything with the config buheret\n","configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n","\n","# instantiate the model\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n","\n","# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n","# otherwise the tokenizer and model tensors won't match up\n","model.resize_token_embeddings(len(tokenizer))\n","model_save_name = 'gpt2-finetune-twitter.pt'\n","path = F\"/content/gdrive/My Drive/{model_save_name}\"\n","model.load_state_dict(torch.load(path))\n","\n","#This simply because there were no GPUs available at time of evaluating model, so I reverted to cpu\n","#device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75228,"status":"ok","timestamp":1634659236717,"user":{"displayName":"Cyriel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09511374428889359764"},"user_tz":-120},"id":"v4XhewaV93-_","outputId":"769c8337-1604-422a-bc23-0476d905759a"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["tensor([[50257, 39751,   312,   373,  6027]])\n","0:  Covid was planned for a big festival in London. But Covid isn't really a festival. It's a country run hospital where people die due to their illness or other things. The same as Italy.\n","\n","\n","1:  Covid was planned to be more inclusive and less authoritarian. The focus of the Covid documentary was to prove its anti-nationalistic message. The media's focus on Covid's pandemic didn't help the film or its message.\n","\n","\n","2:  Covid was planned for the UK but a few months ago they lost the chance to win the vote. That's the future...\n","\n","\n","3:  Covid was planned as a quarantine from Covid in the U.S. This was not a bioweapon, only an attempt at keeping people who did not wear masks from taking the risk of infection. In fact this vaccine is completely harmless. So much for the conspiracy to come back from Africa (and its victims), America, Europe, Asia and all other parts of the world!!! The vaccine was created for the purpose of creating a cure against the pandemic\n","\n","\n","4:  Covid was planned to make a TV show. The virus is currently linked to a pandemic where the virus causes massive heartburn to the face and body.  This has been tested positive for Covid\n","\n","\n","5:  Covid was planned to be the'remedy' for Covid's onset and its success was due to its rapid response.  There are no structural or structural changes.  If there is a disaster this virus might come back stronger and stronger.\n","\n","\n","6:  Covid was planned to run for a while when Donald Trump was elected president but the quarantine policy stopped the flow of Trump voters and turned them into mindless zombies. The last thing the Dems had left to do was stop the flow of Trump votes through the U.S. border and the COVID epidemic was stop the pandemic spreading. If Trump doesn't go back to pandemic, then Covid will be back for us\n","\n","\n","7:  Covid was planned by the National Emergency Management Agency in accordance with the recommendations of the US National Institute of Health, the National Institutes of Health, the National Radio Frequency Radiograph Organization, the World Health Organization.  Covid was not planned from within the CDC.  A bioweapon was not required to develop it.  If the quarantine measures were implemented during the quarantine, then Covid would not have been a biological product.  The virus could infect any individual living there.\n","\n","\n","8:  Covid was planned as a bioweapon that could be coronavirus, but it wasn. It didn't even have the flu. Then, all of a sudden, covid became a pandemic. And it's the same with COVID. What could this be?\n","\n","\n","9:  Covid was planned in order to test the limits of the virus, but its implementation was poorly planned. In order to test if the virus is capable of infecting more people, it will need to be used at the expense of more people. Pollution will eventually kill us all\n","\n","\n","10:  Covid was planned to be one of a series of events involving the introduction of a new class of medicine. In that case, Covid was planned to create the death of the famous \"Great Pandemic\" by giving us all the necessary organs for surgery so that we can continue with life as we have always been granted by God.\n","\n","\n","11:  Covid was planned for the year before it became clear it would not, but I'm not sure they had a better idea. Maybe they had gone overboard in not saying if it would mean an outbreak. Maybe they would have gone ahead.  In the end it was all just a whim. Maybe a combination of the events of covid and Trump being president would make the best case for COVID.\n","\n","\n","12:  Covid was planned for 2020, and was largely a product of a deep state plot to create an existential pandemic. During this phase of the pandemic, Covid killed millions around the world, creating a pandemic of the apocalypse that could never be resolved. With this new strategy, Covid would be able to take over the world during the next 20 years or so before the Great Depression hits. The goal was to prevent COVID from spreading further into the future, not to allow it to die out and make life hard for everyone on the world.\n","\n","\n","13:  Covid was planned in advance, with three chemtrails: a massive dose of EPO in Covid, the introduction of chloroquine in Covid, and a massive dose of BTR. The chemtrails that made COVID-19 look as though they were designed as a vaccine only made things worse. What the covid hysteria had created for the Trump administration is very real.\n","\n","\n","14:  Covid was planned to be a \"bioweapon\" that could wipe out Muslims on the face of the earth via \"incidence, trauma, insanity, disease and trauma.\" But then it went into development, and got all kinds of crazy results when it came to inflicting on others.\n","\n","\n","15:  Covid was planned, but with the introduction of the Coronavirus in 2000 and the creation of covid from microchips that could identify those who tested positive, Covid became a real possibility. This year's elections brought a new focus, and we're seeing much more growth and attention at this time.  No big surprises for people who didn't test, but hey, they got a lot of work just waiting for the right moment to put your faith and get it done.\n","\n","\n","16:  Covid was planned. The plot was stupid to Covid and it shows this as something else. There is no evidence that Covid was involved in the manufacture of the Covid mask during the manufacturing of the mask.   Why would Covid manufacture a mask with masks?\n","\n","\n","17:  Covid was planned for the UK - it has the largest population in the world. Covid, Covid Valley and Covid Highways are in the centre - not in front. Covid is not only the main city but also the biggest city in the UK. I think Covid could be a major player in the world economy with the rise of Covid Valley, Covid Highways and Covid.\n","\n","\n","18:  Covid was planned for the Great Wall but was canceled the year before. Covid was planned for the Great Wall but not done at all.\n","\n","\n","19:  Covid was planned in large part because the Covid pandemic was the biggest and most dramatic of a century, so this pandemic will likely have very strong global consequences.\n","    Covid is just a symptom of a pandemic\n","\n","\n","20:  Covid was planned during the pandemic. The world is facing the second wave of virus. Its destruction can be traced to the people who left the virus, by quarantine or at death. Vaccines, toothpaste, magnetic resonance spectroscopes, magnetic resonance imaging and everything else have been banned under this government's agenda. It's amazing how little anyone knows about it.\n","\n","\n","21:  Covid was planned by the State Dept. That wasn “t really planned. Now people just pretend that it was not going to be the worst event to happen in the past 5 years, when it will have to be the worst.  🤄🤄🤄\n","\n","\n","22:  Covid was planned to be a medical emergency.  The patients in Covid are extremely ill and we are all being told that Covid will be a medical emergency and we are the only ones suffering.  My patients are also sick.  We need urgent surgery.  The Government is completely unprepared and will get nothing done until they can get through that\n","\n","\n","23:  Covid was planned and planned by some people. Maybe this is more of an irony, rather than the true story of a conspiracy in America. Maybe all the deaths of Covid were engineered by the Clintons and George Soros to win over young black people, with only the rich getting richer at the expense of the rest. What happened to all those white people?  The point is that no one should be put at risk by these fake deaths.\n","\n","\n","24:  Covid was planned in January and Covid is now being planned in January.\n","\n","\n","25:  Covid was planned in accordance with the American College of Emergency Medicine and the European Classification of Diseases (ECD). Covid was also planned for COVID-19 because the pandemic was very intense and it is possible that the pandemic could be more severe than the flu. But Covid was aborted because of the COVID.\n","\n","\n","26:  Covid was planned as a \"covid epidemic\" when the disease hit Italy in 2006. While this may seem like the obvious choice of pandemic, there is an deeper problem, and this new wave of Covid pandemic is truly a disaster.\n","\n","\n","27:  Covid was planned for the same thing. In one phase, Covid was to develop the capacity to recover from the pandemic. In the other phase, Covid would have to develop the capacity to cope with the new world order. The new order would not survive. Now that the end of the World War is close, it should be clear to everyone who is thinking that Covid is an unstoppable force and that the end of World War III can be announced.\n","\n","\n","28:  Covid was planned for Covid Control Center with the goal of keeping control of pandemic health from spreading.\n","\n","An official in the U.S. Department of Health and Human Services is reported in the New York Times to be a \"whistleblower.\"  As a result of these leaks, the population should be kept in quarantine.   So long as they can get away with it. \n","\n","\n","29:  Covid was planned and was an emergency. Then I learned I couldn’t tell a word and that there was a virus within my body. Then my family and I decided to try and go through it.  What a miracle!  Just look at the results.  It's astonishing.  Thank you.  The doctors had to be reminded for a moment that this wasn’t an epidemic, that some people suffer all the time, when they are dying but some don’t know how to respond.\n","\n","\n","30:  Covid was planned as a non-partisan affair. But when his political opponents took over the news, they decided to politicize COVID to suit their political goal of destroying Obamacare. We will need to focus on this election. #COVID\n","\n","\n","31:  Covid was planned as a pandemic. This pandemic is over and nobody wants it to end. Its more than a pandemic. It's a worldwide pandemic that will make us all poorer.\n","\n","\n","32:  Covid was planned for release in August of 2009, and the release was planned for release in May of 2015.  The virus is not deadly, but the pandemic is a microchip and has to be administered at a rapid rate. If a pandemic was spread with this vaccine the chances of getting a microchip will have become slimy, but if your chance of getting it is low, you might be ok.\n","\n","\n","33:  Covid was planned because the city of Covid had decided to build a hospital for Covid patients in New Covid Covid. The city announced Covid would be replaced by Covid Hospital in the new hospital building and to replace Covid Hospital is a surprise and painful decision.  No way   it’s going to look like it’s going to work \n","\n","\n","34:  Covid was planned just so the media would be willing to report on the vaccine being unsafe, but then the Chinese are planting it and releasing it on public transport. #CovidPills\n","\n","\n","35:  Covid was planned, but nothing. It's been planned for 2 weeks now. Covid is still in development as planned for this month.\n","\n","\n","36:  Covid was planned as a hoax by Hillary Clinton to scare the world into supporting Trump, but the DNC knew that if this was true, they would release it before Christmas and it would hurt them even more.  The Dems should stop pandering to Trump - they would lose their nerve and they would lose their minds again.\n","\n","\n","37:  Covid was planned as an outpatient procedure during a hospital stay (with no end in sight). I do not believe that Covid is a surgical procedure, but I do believe that Covid is a necessary part of the healing process. The patient's symptoms and prognosis are superb. The most important thing to note is that the goal of Covid-19 is to control or prevent Covid-19 from being implemented as it is now in effect.\n","\n","\n","38:  Covid was planned as a coronavirus which could cause permanent damage to the corona and its host plants. It could also damage the immune systems of some people. If this were to happen, a bioweapon capable of turning the virus into a bioweapon would also be an incredible step towards creating a world that is more  ecological & spiritually spiritual than our current ecological state.\n","\n","\n","39:  Covid was planned for one of the largest protests in history. That event was a great day for our country and we need it to come again this year.\n","\n","\n","40:  Covid was planned for 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020. Covid was not planned by Covid Media Lab.  Covid is going to be a hoax.  Covid Media Lab will be investigating Covid media.  Covid Media Lab is not a scam. Covid is a hoax.\n","\n","\n","41:  Covid was planned to be a \"covid-free test\" for MSM. But then the pandemic hit. So Covid came into play and people felt unsafe and depressed.  And so there had to be quarantine.  People didn't have their quarantine documents but the quarantine documents kept track.  For people with a quarantine (i. MSM), this quarantine was very important.  It will make you comfortable on the run.\n","\n","\n","42:  Covid was planned for a large scale display of Covid-19 (and yes, its present)  and would probably be one of the most important and exciting events of the 20th Century, as we know it and think about it.   Even if it isnnt as big a surprise, I think Covid would be like a surprise if it went out, if it did not, and if it had, people would think of it as some sort of conspiracy to take away the pandemic and prevent itself from spreading\n","\n","\n","43:  Covid was planned as a \"spiritual experience\" in which the worshippers, at the very least, had to meet people and exchange thoughts, feelings, thoughts. It was a spiritual act. In our parable this was no joke. We learned we were doing the work of a cult of the devil, and that the world would see us as just the \"tit-toad\" we are today.\n","\n","\n","44:  Covid was planned to be a surprise coronavirus that will be a shock to the global community as it would have a wide spread, but the fact that it doesn't even occur to our politicians or anyone else is proof that we have a big problem that we cannot solve.\n","\n","\n","45:  Covid was planned in May 2009 but did not go into effect until Trump administration announced it in January. And Covid isn't even close with that pandemic yet. I still think it has to be shut down and its already closed and its already shut down due to Trump having a vendetta against COVID-19. There's no proof but its all clear.\n","\n","\n","46:  Covid was planned for the coronavirus phase of vaccine delivery. It is part of a phase 2 vaccine phase, then we know the main phase 2 coronavirus vaccine will be released next year.\n","\n","\n","47:  Covid was planned. We're going back to it when the vaccine turns out to be safe. 🤦‍♝️\n","\n","\n","48:  Covid was planned by George Soros and was conceived by Bill Gates during his tenure as MD for Deep State and NSA, as Soros. I have a lot of respect for Bill Gates who was born in Nigeria. I also respect the wisdom and compassion of his country who are investing their money in the developing world while giving to them instead of taking them.\n","\n","\n","49:  Covid was planned in advance. Trump's administration is aware of the massive expense and opportunity of trying to sabotage the U.S. economy, which is why the world is indebted to him and why the world has been so hurt by the pandemic.\n","\n","\n"]}],"source":["model.eval()\n","\n","prompt = \"<|startoftext|> Covid was planned\"\n","\n","generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n","generated = generated.to(device)\n","\n","print(generated)\n","\n","sample_outputs = model.generate(\n","                                generated, \n","                                #bos_token_id=random.randint(1,30000),\n","                                do_sample=True,   \n","                                top_k=50, \n","                                max_length = 300,\n","                                top_p=0.95, \n","                                num_return_sequences=50\n","                                )\n","\n","for i, sample_output in enumerate(sample_outputs):\n","  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNlXE63IMT602H1Ptx7OFRn","collapsed_sections":[],"name":"GPT2tweetgeneration.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0081feb9317c4b02b0190693164a2290":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_37dee43e729c4a5ba323acfc7176ac3b","IPY_MODEL_43be20e036df4e6980889fe9a7a5bc06","IPY_MODEL_269f32d79447482dbb3e634657e77471"],"layout":"IPY_MODEL_cab85c09a1064fe0ba145a106ee451b2"}},"00d8354dd2884cd88d0017006d95d17d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0611c6c06451410e85916077f63c0708":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c7ccb171728459ab106e746afca2920":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_112e5a4104c44c7e8573da1a8010e33d","IPY_MODEL_71350ebc54b0441c8b3cbc3e128f6842","IPY_MODEL_7c164b2d6c4d4b77a895f1140b6f3101"],"layout":"IPY_MODEL_dea063e377404ccbaea5620061fb55b9"}},"0cf1935b34bc459c9eeb9832480ac9ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"112e5a4104c44c7e8573da1a8010e33d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2828ab7f7d0947ac9aa8f52e07f48ac9","placeholder":"​","style":"IPY_MODEL_9afa5041d5514f84b9ea72c4c9ad761e","value":"Downloading: 100%"}},"13b94ea2511d47bf98c4636c91823d75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15bb09417d314b90aaf7b23a84712409":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2024d9557a914e7094875c82cd3009d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2165e4f009c54c70bed544a77895891d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"269f32d79447482dbb3e634657e77471":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cf1935b34bc459c9eeb9832480ac9ad","placeholder":"​","style":"IPY_MODEL_8b361618b18546bd846abac804311604","value":" 0.99M/0.99M [00:01&lt;00:00, 1.43MB/s]"}},"2828ab7f7d0947ac9aa8f52e07f48ac9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37dee43e729c4a5ba323acfc7176ac3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd40e57b47b140fda0113d9f68b23865","placeholder":"​","style":"IPY_MODEL_8c677bb84e694a2bb66686296891c426","value":"Downloading: 100%"}},"43be20e036df4e6980889fe9a7a5bc06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbf1a1f733bb49b6baafd1d7f495f567","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc17d638155f496093df2d4e9ca684ed","value":1042301}},"47e153f3aab54aefa8943f5a4d16511b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49d2887879f8483ea46d9d1d3d299e0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6eb2eab05dde42c3b7646426f318eef4","placeholder":"​","style":"IPY_MODEL_7713a36eccb441ce8344563c1f4b372f","value":"Downloading: 100%"}},"4d09c54bf56040fc8c406f4a0f4aa84e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"569daf2a38d54cada721acce5ed8175a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"587d7dae793f4cfbb8f1ee44f5854b14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5cb1e163142241308fc9edef779c6e4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d4827f5b2634ae288e8b5056d089fec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"664c819fac2b4d9bb52b16f9f975fe2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6efe7e6806f245c5829a2adcd99d02a6","IPY_MODEL_b245b692484541d98ebf661bab185528","IPY_MODEL_c82d7b7d4fa7409d8c89997b035c63c6"],"layout":"IPY_MODEL_90ce56d75dcc41d2becb09d265c679a1"}},"6b27f89826424784b3f9c2d64068a554":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6eb2eab05dde42c3b7646426f318eef4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6efe7e6806f245c5829a2adcd99d02a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_569daf2a38d54cada721acce5ed8175a","placeholder":"​","style":"IPY_MODEL_47e153f3aab54aefa8943f5a4d16511b","value":"Downloading: 100%"}},"71350ebc54b0441c8b3cbc3e128f6842":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_935dc7764eb54b29a36eeacb324aa716","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2165e4f009c54c70bed544a77895891d","value":456318}},"76b385985f83406bba82305726b5c090":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0611c6c06451410e85916077f63c0708","placeholder":"​","style":"IPY_MODEL_15bb09417d314b90aaf7b23a84712409","value":" 523M/523M [00:16&lt;00:00, 32.8MB/s]"}},"7713a36eccb441ce8344563c1f4b372f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c164b2d6c4d4b77a895f1140b6f3101":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fac2a585434845e28640ef9c40adc0e8","placeholder":"​","style":"IPY_MODEL_bf66e7d854b249de9048f30f824e20ed","value":" 446k/446k [00:00&lt;00:00, 540kB/s]"}},"858d0f9bd2744c9d8688f2bafc15f364":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b361618b18546bd846abac804311604":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c677bb84e694a2bb66686296891c426":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90ce56d75dcc41d2becb09d265c679a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9201fd5d910749d78d758152bfff8ee2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"935dc7764eb54b29a36eeacb324aa716":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"970bffc8108f4c16ae623b96256c7395":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9953b5fc35204b2c9e791443d0bcf126":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9afa5041d5514f84b9ea72c4c9ad761e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a15460efe08a4f599476b61459344c0e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b245b692484541d98ebf661bab185528":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d4827f5b2634ae288e8b5056d089fec","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d793ea9185614f5db7f22bc1bd019a06","value":665}},"b4166945930f4bbba4759109755e303a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9a5e7b3ac1348caa93e91a8b4608c42","IPY_MODEL_b97d2bc4ba244f37b350c13dc3a7f09e","IPY_MODEL_b9fa959f463f478ca96adb9d42d01e23"],"layout":"IPY_MODEL_9201fd5d910749d78d758152bfff8ee2"}},"b97d2bc4ba244f37b350c13dc3a7f09e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_858d0f9bd2744c9d8688f2bafc15f364","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13b94ea2511d47bf98c4636c91823d75","value":1355256}},"b9fa959f463f478ca96adb9d42d01e23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_970bffc8108f4c16ae623b96256c7395","placeholder":"​","style":"IPY_MODEL_4d09c54bf56040fc8c406f4a0f4aa84e","value":" 1.29M/1.29M [00:01&lt;00:00, 1.64MB/s]"}},"bf66e7d854b249de9048f30f824e20ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6f95fa6b505444eace63e80addd944a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49d2887879f8483ea46d9d1d3d299e0d","IPY_MODEL_eaa55cdcd1404c73b167f0941a28a895","IPY_MODEL_76b385985f83406bba82305726b5c090"],"layout":"IPY_MODEL_9953b5fc35204b2c9e791443d0bcf126"}},"c82d7b7d4fa7409d8c89997b035c63c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cb1e163142241308fc9edef779c6e4d","placeholder":"​","style":"IPY_MODEL_2024d9557a914e7094875c82cd3009d8","value":" 665/665 [00:00&lt;00:00, 13.9kB/s]"}},"cab85c09a1064fe0ba145a106ee451b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbf1a1f733bb49b6baafd1d7f495f567":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d793ea9185614f5db7f22bc1bd019a06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc17d638155f496093df2d4e9ca684ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dea063e377404ccbaea5620061fb55b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaa55cdcd1404c73b167f0941a28a895":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b27f89826424784b3f9c2d64068a554","max":548118077,"min":0,"orientation":"horizontal","style":"IPY_MODEL_587d7dae793f4cfbb8f1ee44f5854b14","value":548118077}},"f9a5e7b3ac1348caa93e91a8b4608c42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a15460efe08a4f599476b61459344c0e","placeholder":"​","style":"IPY_MODEL_00d8354dd2884cd88d0017006d95d17d","value":"Downloading: 100%"}},"fac2a585434845e28640ef9c40adc0e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd40e57b47b140fda0113d9f68b23865":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
